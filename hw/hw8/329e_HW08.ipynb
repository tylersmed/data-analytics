{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 8 - k-Nearest Neighbors (kNNs)\n",
    "(20 points)\n",
    "\n",
    "### Add your name(s) and EIDs below\n",
    "- Student Name:\n",
    "- Student UT EID:\n",
    "- Partner Name:\n",
    "- Partner UT EID:\n",
    "\n",
    "\n",
    "# k-Nearest Neighbors\n",
    "For this assignment, we are going explore one new classification technique: k nearest neighbors.\n",
    "\n",
    "We are using a different version of the Melbourne housing data set from earlier in the semester, split into training and testing sets for you. Our goal is to predict the housing type as one of three possible categories:\n",
    "\n",
    "  - 'h' house\n",
    "  - 'u' duplex\n",
    "  - 't' townhouse\n",
    "\n",
    "At the end of this homework, you will understand how to build and use a kNN model, and improve your data cleaning and data preparation skills. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the libraries you will use for this assignment.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import calendar\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start off by loading the training dataset.\n",
    "df_melb = pd.read_csv('melb_data_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 \n",
    "\n",
    "**Fix our \"Date\" column to be numeric**: If we inspect our dataframe `df_melb` using the `dtypes` property, we see that the column `Date` is an `object`.  However, we think this column might contain useful information, so your goal is to convert it to [Unix time](https://en.wikipedia.org/wiki/Unix_time).\n",
    "\n",
    "Unix time is the number of secconds since a fixed time known as the \"Unix epoch\", which is midnight on January 1st, 1970. For example, the Unix time for March 10th, 2023 is 1,678,474,369 seconds.\n",
    "\n",
    "- **Use only the libraries imported above** imported libraries to create a new column `UnixTime`. \n",
    "    - Be careful, the date strings in the file might have some non-uniform formatting that you have to fix first.  \n",
    "- Print out the min and max epoch time to check your work.  \n",
    "- Drop the original `Date` column. \n",
    "\n",
    "The Python [reference for time](https://docs.python.org/3/library/time.html) can help you with your conversion to Unix time.\n",
    "\n",
    "(**3 points**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reference, here are the data types of each column.\n",
    "df_melb.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def standardize_date(date_string):\n",
    "    \"\"\"Standardize a date string to a standard format.\n",
    "\n",
    "    Rules:\n",
    "    - You can assume the input string is of the form day/month/year.\n",
    "    - Fixed date strings should be of the form DD/MM/YYYY. If a day is\n",
    "      one digit, append zeros.\n",
    "    - If the input string's year is two digits (e.g. 02), assume\n",
    "      the year is in the 2000s (e.g. 2002).\n",
    "    \"\"\"\n",
    "    fixed_date_string = ...\n",
    "    return fixed_date_string\n",
    "\n",
    "def replace_date_with_unix(df):\n",
    "    \"\"\"Given a Melbourne dataset dataframe, replace the Date column\n",
    "    with a UnixTime column.\n",
    "\n",
    "    Hint: Call standardize_date within this function.\n",
    "    \"\"\"\n",
    "    # Standardize the date column.\n",
    "    ...\n",
    "    # Create the UnixTime column\n",
    "    ...\n",
    "    # Drop the date column.\n",
    "    df = ...\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_melb_q1 = replace_date_with_unix(df_melb)\n",
    "\n",
    "# Print the cleaned UnixTime values.\n",
    "print('Min UnixTime:', df_melb_q1['UnixTime'].min())\n",
    "print('Max UnixTime:', df_melb_q1['UnixTime'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Q2 \n",
    "\n",
    "**Use imputation to fill in missing values**: kNN doesn't work when some attributes are not present, so we must fill in all the missing values in `df_melb` with something. As a simple estimate, we will fill in missing values with the **mean** of that value/column.\n",
    "\n",
    "What we're trying to classify ('h'ome/'d'u'plex/'t'ownhouse), also knonw as the **target**, is store in the `Type` column. We define a variable `target_col` which lets you automatically infer which column is the target. During imputation, we should skip this target column.\n",
    "\n",
    "- Use `df_melb_q1`, i.e. the result from Q1.\n",
    "- Save the mean of each column in a dictionary `dict_imputation`. Keys are an attribute's column name, and values are that attribute's mean.\n",
    "- Use `dict_imputation` to imputate the missing values in `df_melb_q1`.\n",
    "- Store the imputated dataframe in `df_melb_q2`.\n",
    "\n",
    "(**3 points**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_imputation_dict(df, target_col):\n",
    "    \"\"\"Collect the mean values of each column, excluding NaN values\n",
    "    and the target column.\n",
    "    \"\"\"\n",
    "    dict_imputation = {}\n",
    "\n",
    "    # Get the mean value of each column.\n",
    "    ...\n",
    "    return dict_imputation\n",
    "\n",
    "def imputate(df, dict_imputation, target_col):\n",
    "    \"\"\"Imputate a dataframe, replacing missing values with those\n",
    "    given in dict_imputation. Do not imputate target_col.\"\"\"\n",
    "    df = ...\n",
    "    ...\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the target column as a string\n",
    "target_col = ...\n",
    "\n",
    "# Collect imputation values\n",
    "dict_imputation = build_imputation_dict(df_melb_q1, target_col)\n",
    "\n",
    "# Imputate the dataframe\n",
    "df_melb_q2 = imputate(df_melb_q1, dict_imputation, target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check your results\n",
    "dict_imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check your results\n",
    "df_melb_q2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Q3\n",
    "\n",
    "**Normalize all attributes to be between [0,1]**: Normalize all the attribute columns in `df_melb_q2` so they have a value between zero and one (inclusive). \n",
    "\n",
    "To do this, we will build a dictionary `dict_normalize`, with column names for keys and (min, max) tuples for values, which are the min (resp. max) value found in the dataframe for that column. Just like in Q2, we do not normalize the target column.\n",
    "\n",
    "After creating `dict_normalize`, we will use it to normalize each column and generate a new dataframe, `df_melb_q3`. The resulting dataframe is now your model that you can use to classify new data points.\n",
    "\n",
    "- Use `df_melb_q2`, i.e. the result from Q2.\n",
    "- Save the minimum and maximum values of each column in a dictionary `dict_normalize`. Keys are an attribute's column name, and values are a (min, amx) tuple for that column,\n",
    "- Use `dict_normalize` to normalize the missing values in `df_melb_q2`.\n",
    "- Store the imputated dataframe in `df_melb_q3`.\n",
    "\n",
    "(**3 points**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_normalization_dict(df, target_col):\n",
    "    \"\"\"Collect the (min, max) values of each column, except the\n",
    "    target column.\n",
    "    \"\"\"\n",
    "    dict_normalize = {}\n",
    "\n",
    "    # Get the min and max values of each column.\n",
    "    ...\n",
    "    return dict_normalize\n",
    "\n",
    "def normalize(df, dict_normalize, target_col):\n",
    "    \"\"\"Normalize a dataframe, setting all values to the range [0, 1]\n",
    "    using (min, max) values in dict_normalize. Do not normalize target_col.\"\"\"\n",
    "    df = ...\n",
    "    ...\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the target column as a string\n",
    "target_col = ...\n",
    "\n",
    "# Collect normalization values\n",
    "dict_normalize = build_normalization_dict(df_melb_q2, target_col)\n",
    "\n",
    "# Normalize the dataframe\n",
    "df_melb_q3 = normalize(df_melb_q2, dict_normalize, target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check your results\n",
    "dict_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check your results\n",
    "df_melb_q3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Q4 \n",
    "\n",
    "**Prepare the test data**: Load in `melb_data_test.csv` and repeat the steps in Q1, Q2, and Q3 (unix time, imputation, and normalization).\n",
    "\n",
    "(**1 point**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the test dataframe\n",
    "df_melb_test = ...\n",
    "\n",
    "# Clean the dates, add unix time\n",
    "df_melb_test = replace_date_with_unix(df_melb_test)\n",
    "\n",
    "# Imputate the dataframe\n",
    "target_col = ...\n",
    "dict_imputation_test = ...\n",
    "df_melb_test = ...\n",
    "\n",
    "# Normalize the dataframe\n",
    "dict_normalize_test = ...\n",
    "df_melb_test = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check your results\n",
    "df_melb_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Q5\n",
    "\n",
    "**Write the kNN classifier function**: Your function, `predict_knn` will take in the following four parameters:\n",
    "- Training dataframe `df_train`\n",
    "- Hyperparameter `k`\n",
    "- Testing sample `test_sample` (one row of the DataFrame, we can generate it using `iloc` or `iterrows`).\n",
    "- Target column string `target_col`, which defines the variable we want to predict.\n",
    "\n",
    "It will predict which class `test_sample` belongs to, based on the `k` nearest neighbors to the sample.\n",
    "\n",
    "- We assume `df_train` is normalized/imputated, contains all attributes, and also contains the target column.\n",
    "- Likewise, we assume `test_sample` is normalized/imputated and contains all attributes. (But, it does not have to have the target column).\n",
    "\n",
    "*Hint*: To find the distance between the test sample and any element of the training dataset, you may use the [L2 norm function from numpy](https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html).\n",
    "\n",
    "(**5 points**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_knn(df_train: pd.DataFrame, k: int, \n",
    "                test_sample: pd.Series, target_col: str):\n",
    "    \"\"\"Use the k-nearest neighbors algorithm to predict the class of a test-sample,\n",
    "    given a training set.\n",
    "    \n",
    "    Parameters:\n",
    "        df_train:    DataFrame of training samples\n",
    "        k:           Number of neighbors to consider\n",
    "        test_sample: Single evaluation sample\n",
    "        target_col:  Name of the target variable (column)\n",
    "\n",
    "    Returns:\n",
    "        prediction: Predicted class of the test sample using kNN.\n",
    "    \"\"\"\n",
    "    ...\n",
    "    prediction = ...\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Q6 \n",
    "\n",
    "**Compute the accuracy using different k values**: For each value of $k$ in the set $\\{1,3,13,25,50,100\\}$, compute the kNN prediction for each oberservation in the test set, and the overall accuracy of the classifier.  Plot the accuracy as a function of $k$.\n",
    "\n",
    "- Use your imputed, normalize training dataframe (`df_melb_q3`).\n",
    "- Use your imputed, normalized testing dataframe (`df_melb_test`).\n",
    "- Have an outer loop over the k-values, and an inner loop computing the prediction for each testing sample under that k-value.\n",
    "\n",
    "Which value of $k$ would you choose? Why?\n",
    "\n",
    "(This can take a while to run; probably at least 5-10 minutes.)\n",
    "\n",
    "(**5 points - 3 for implementation, 1 for plot, 1 for description**).\n",
    "\n",
    "(**This question will be manually graded.**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_ignore"
    ]
   },
   "outputs": [],
   "source": [
    "# Sweep over the k-values. Place your accuracies for each k-value in acc_k.\n",
    "poss_k = [1, 3, 13, 25, 50, 100]\n",
    "acc_k = []\n",
    "\n",
    "# Your code goes below.\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_ignore"
    ]
   },
   "outputs": [],
   "source": [
    "# Plot your accuracies for each k-value.\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "otter": {
   "OK_FORMAT": true,
   "assignment_name": "329e_HW08",
   "tests": {
    "q1": {
     "name": "q1",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": 3,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": 1,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": 5,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "05642a42904bc69a6f3fb292ea6dbf0463ee768c41640775e87375f7653a91c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
