{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 7\n",
    "\n",
    "## Your Name Here (or your names here if you are pair programming)\n",
    "\n",
    "Student Name: Tyler Smedley\n",
    "\n",
    "Student UT EID: tws933\n",
    "\n",
    "---\n",
    "\n",
    "Partner Name:\n",
    "\n",
    "Partner UT EID:\n",
    "\n",
    "---\n",
    "\n",
    "Date Created: 03/18/24\n",
    "\n",
    "Date Last Modified:\n",
    "\n",
    "---\n",
    "\n",
    "Totoal Points 20. \n",
    "\n",
    "\n",
    "\n",
    "## Supprt Vector Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Headers\n",
    "# You are welcome to add additional headers here if you wish\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Enable inline mode for matplotlib so that Jupyter displays graphs\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your allowed to use only the above libraries that are imported. No other libs should be used in this assignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Dataset \n",
    "\n",
    "In this Assignment we will work with some patients dataset. \n",
    "\n",
    "We have access to 303 patients data. The features are listed below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPain</th>\n",
       "      <th>RestBP</th>\n",
       "      <th>Chol</th>\n",
       "      <th>Fbs</th>\n",
       "      <th>RestECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExAng</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Thal</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>typical</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>nonanginal</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>nontypical</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>typical</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>nontypical</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>nonanginal</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Sex     ChestPain  RestBP  Chol  Fbs  RestECG  MaxHR  ExAng  \\\n",
       "0     63    1       typical     145   233    1        2    150      0   \n",
       "1     67    1  asymptomatic     160   286    0        2    108      1   \n",
       "2     67    1  asymptomatic     120   229    0        2    129      1   \n",
       "3     37    1    nonanginal     130   250    0        0    187      0   \n",
       "4     41    0    nontypical     130   204    0        2    172      0   \n",
       "..   ...  ...           ...     ...   ...  ...      ...    ...    ...   \n",
       "298   45    1       typical     110   264    0        0    132      0   \n",
       "299   68    1  asymptomatic     144   193    1        0    141      0   \n",
       "300   57    1  asymptomatic     130   131    0        0    115      1   \n",
       "301   57    0    nontypical     130   236    0        2    174      0   \n",
       "302   38    1    nonanginal     138   175    0        0    173      0   \n",
       "\n",
       "     Oldpeak  Slope   Ca        Thal Target  \n",
       "0        2.3      3  0.0       fixed     No  \n",
       "1        1.5      2  3.0      normal    Yes  \n",
       "2        2.6      2  2.0  reversable    Yes  \n",
       "3        3.5      3  0.0      normal     No  \n",
       "4        1.4      1  0.0      normal     No  \n",
       "..       ...    ...  ...         ...    ...  \n",
       "298      1.2      2  0.0  reversable    Yes  \n",
       "299      3.4      2  2.0  reversable    Yes  \n",
       "300      1.2      2  1.0  reversable    Yes  \n",
       "301      0.0      2  1.0      normal    Yes  \n",
       "302      0.0      1  NaN      normal     No  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "heart_df = pd.read_csv(\"Heart.csv\")\n",
    "heart_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Age:** The personâ€™s age in years\n",
    "\n",
    "**Sex:** The personâ€™s sex (1 = male, 0 = female)\n",
    "\n",
    "**ChestPain:** chest pain type\n",
    "\n",
    "* Value 0: asymptomatic\n",
    "* Value 1: atypical angina\n",
    "* Value 2: non-anginal pain\n",
    "* Value 3: typical angina\n",
    "\n",
    "**RestBP:** The personâ€™s resting blood pressure (mm Hg on admission to the hospital)\n",
    "\n",
    "**Chol:** The personâ€™s cholesterol measurement in mg/dl\n",
    "\n",
    "**Fbs:** The personâ€™s fasting blood sugar (> 120 mg/dl, 1 = true; 0 = false)\n",
    "restecg: resting electrocardiographic results\n",
    "\n",
    "* Value 0: showing probable or definite left ventricular hypertrophy by Estesâ€™ criteria\n",
    "* Value 1: normal\n",
    "* Value 2: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
    "\n",
    "**RestECG:** The personâ€™s maximum heart rate achieved\n",
    "\n",
    "**MaxHR:** Exercise induced angina (1 = yes; 0 = no)\n",
    "\n",
    "**Oldpeak:** ST depression induced by exercise relative to rest (â€˜STâ€™ relates to positions on the ECG plot. See more here)\n",
    "\n",
    "**Slope:** the slope of the peak exercise ST segment â€” 0: downsloping; 1: flat; 2: upsloping\n",
    "\n",
    "* 0: downsloping; \n",
    "* 1: flat; \n",
    "* 2: upsloping\n",
    "\n",
    "**Ca:** The number of major vessels (0â€“3)\n",
    "\n",
    "**Thal:** A blood disorder called thalassemia Value 0: NULL (dropped from the dataset previously\n",
    "\n",
    "* Value 1: fixed defect (no blood flow in some part of the heart)\n",
    "* Value 2: normal blood flow\n",
    "* Value 3: reversible defect (a blood flow is observed but it is not normal)\n",
    "\n",
    "**Target:** Heart disease (1 = no, 0= yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task - 1 Implement SVM using libraries (4 points)\n",
    "We want to use **Suppert Vector Machine** to perdict if the patients will have heart problems or not. The column \"Target\" in our datasets includes data about heart diseases. If the patient had heart disease we have a 1 and if not a zero. \n",
    "\n",
    "Prepare your data set for predicting heart disease (\"Target\" column) out of 3 features:\n",
    "\n",
    "* Age of the patient (Column **\"Age\"**)\n",
    "* Gender of the patient (male or female - Column **\"Sex\"**)\n",
    "* Cholestrol level of the patient (Column **\"Chol\"**) \n",
    "\n",
    "\n",
    "Split your data into 80% traning data and 20% test data, and implement Support Vector Machine using Scikit-Learn. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target yes/no to 1/0 and create test/train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "heart_df['Target'] = heart_df['Target'].map({'Yes':1, 'No':0})\n",
    "y = heart_df['Target']\n",
    "X = heart_df[['Age', 'Sex', 'Chol']]\n",
    "\n",
    "y_train, y_test, X_train, X_test = train_test_split(y, X, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn's svm model, fit training data, and predict target values from test data\n",
    "from sklearn import svm\n",
    "\n",
    "svm_model  = svm.SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "target_pred = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 - (4 points)\n",
    "\n",
    "Cacluate the accuracy, Precision, Recall and F1 score of your **SVM** implementaion from Task 1. \n",
    "Print the results. \n",
    "\n",
    "You may use library methods for this task if you choose to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.69      0.62        35\n",
      "           1       0.39      0.27      0.32        26\n",
      "\n",
      "    accuracy                           0.51        61\n",
      "   macro avg       0.47      0.48      0.47        61\n",
      "weighted avg       0.49      0.51      0.49        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use sklearn to calculate and print accuracy, precision, recall, and F1 score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, target_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 - Implement SVM without using libraries  - (4 points)\n",
    "\n",
    "Implement SVM from scratch using Hinge Loss function and Gradient Descent. \n",
    "Try to produce the same result as you get from the libraries. \n",
    "\n",
    "\n",
    "* Do as many iterations as needed \n",
    "* Do maximum **100 iterations**\n",
    "* Use a very small learning rate for checking your GD implementation. \n",
    "* Your are allowed to use your choice of learning rate, like using 0.0001, 0.001 or 0.01 or 0.1 or higher. \n",
    "* Visualize your costs. \n",
    "* No need to add an y-intercept in this task. \n",
    "* You can use libraries to report accuracy, Precision, Recall and F1. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:\n",
    "    # manualy implement train_test_split\n",
    "    # convert categorical variables to numerical\n",
    "    # Convert X data frame to numpy style array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[156,\n",
       " 49,\n",
       " 46,\n",
       " 133,\n",
       " 129,\n",
       " 290,\n",
       " 194,\n",
       " 199,\n",
       " 246,\n",
       " 301,\n",
       " 250,\n",
       " 127,\n",
       " 11,\n",
       " 242,\n",
       " 182,\n",
       " 39,\n",
       " 21,\n",
       " 230,\n",
       " 105,\n",
       " 151,\n",
       " 179,\n",
       " 14,\n",
       " 161,\n",
       " 104,\n",
       " 296,\n",
       " 283,\n",
       " 73,\n",
       " 3,\n",
       " 140,\n",
       " 269,\n",
       " 13,\n",
       " 63,\n",
       " 202,\n",
       " 146,\n",
       " 95,\n",
       " 214,\n",
       " 286,\n",
       " 25,\n",
       " 38,\n",
       " 86,\n",
       " 291,\n",
       " 60,\n",
       " 229,\n",
       " 292,\n",
       " 260,\n",
       " 113,\n",
       " 239,\n",
       " 71,\n",
       " 31,\n",
       " 20,\n",
       " 82,\n",
       " 267,\n",
       " 37,\n",
       " 10,\n",
       " 125,\n",
       " 274,\n",
       " 191,\n",
       " 256,\n",
       " 219,\n",
       " 244]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "# creating a new data frame for the manual implementation\n",
    "heart_2 = pd.read_csv('Heart.csv')\n",
    "heart_2['Target'] = heart_2['Target'].map({'Yes':1, 'No': -1})\n",
    "random_test_indices = random.sample(range(0, heart_2.shape[0]), int(heart_2.shape[0] * 0.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute cost here\n",
    "def compute_cost(X, y, W, reg_factor):\n",
    "    n = X.shape[1]\n",
    "    distances = 1 - y *(np.dot(X, W))\n",
    "    distances[distances < 0] = 0\n",
    "\n",
    "    hinge_loss = reg_factor * (np.sum(distances) / n)\n",
    "    return (np.dot(W, W) + hinge_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate gradient\n",
    "def calculate_gradient(X, y, W, reg_factor):\n",
    "    if type(y) == np.float64:\n",
    "        y = np.array([y])\n",
    "        X = np.array([X])\n",
    "\n",
    "    distance = 1 - (y * np.dot(X, W))\n",
    "    dw = np.zeros(len(W))\n",
    "\n",
    "    for ind, d  in enumerate(distance):\n",
    "        if d < 0:\n",
    "            di = W\n",
    "        else:\n",
    "            di = W - (reg_factor * y[ind] * X[ind])\n",
    "        dw += di\n",
    "\n",
    "    dw = dw/len(y)\n",
    "    return dw\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age  Sex  Chol\n",
      "74    44    1   197\n",
      "153   55    1   289\n",
      "64    54    1   188\n",
      "296   59    1   176\n",
      "287   58    1   220\n",
      "..   ...  ...   ...\n",
      "251   58    1   218\n",
      "192   43    1   247\n",
      "117   35    0   183\n",
      "47    50    1   243\n",
      "172   59    0   249\n",
      "\n",
      "[242 rows x 3 columns]\n",
      "Epoch 0 Cost is: 0.8066666666666668 weights [0. 0. 0.]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, i, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCost is:\u001b[39m\u001b[38;5;124m\"\u001b[39m, cost, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m, weights)\n\u001b[1;32m     14\u001b[0m cost_list\u001b[38;5;241m.\u001b[39mappend(cost)\n\u001b[0;32m---> 15\u001b[0m gradient \u001b[38;5;241m=\u001b[39m calculate_gradient(X_train, y_train, weights, regularization)\n\u001b[1;32m     17\u001b[0m weights \u001b[38;5;241m=\u001b[39m weights \u001b[38;5;241m-\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m gradient\n",
      "Cell \u001b[0;32mIn[10], line 14\u001b[0m, in \u001b[0;36mcalculate_gradient\u001b[0;34m(X, y, W, reg_factor)\u001b[0m\n\u001b[1;32m     12\u001b[0m         di \u001b[38;5;241m=\u001b[39m W\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 14\u001b[0m         di \u001b[38;5;241m=\u001b[39m W \u001b[38;5;241m-\u001b[39m (reg_factor \u001b[38;5;241m*\u001b[39m y[ind] \u001b[38;5;241m*\u001b[39m X[ind])\n\u001b[1;32m     15\u001b[0m     dw \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m di\n\u001b[1;32m     17\u001b[0m dw \u001b[38;5;241m=\u001b[39m dw\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3796\u001b[0m     ):\n\u001b[1;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "weights  = np.zeros(X.shape[1])\n",
    "y_train = np.where(y_train==0, -1, 1)\n",
    "print(X_train)\n",
    "\n",
    "# optimize SVM using gradient descent\n",
    "num_iterations = 100\n",
    "learning_rate = 0.01\n",
    "regularization = 0.01\n",
    "cost_list = []\n",
    "\n",
    "for i in range(0, num_iterations):\n",
    "    cost = compute_cost(X_train, y_train, weights, regularization)\n",
    "    print(\"Epoch\", i, \"Cost is:\", cost, \"weights\", weights)\n",
    "    cost_list.append(cost)\n",
    "    gradient = calculate_gradient(X_train, y_train, weights, regularization)\n",
    "    \n",
    "    weights = weights - learning_rate * gradient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4 - Compare SVM results with Logistic Regression - (4 points)\n",
    "\n",
    "Which model performs better here? Compare your results wit the logistic regression. You can use libraries for this task, it is not necessary to implement logistic regression from sratch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         0\n",
      "           0       0.00      0.00      0.00        35\n",
      "           1       0.69      0.77      0.73        26\n",
      "\n",
      "    accuracy                           0.33        61\n",
      "   macro avg       0.23      0.26      0.24        61\n",
      "weighted avg       0.29      0.33      0.31        61\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tylers/anaconda3/envs/env_full/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tylers/anaconda3/envs/env_full/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tylers/anaconda3/envs/env_full/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tylers/anaconda3/envs/env_full/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tylers/anaconda3/envs/env_full/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/tylers/anaconda3/envs/env_full/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predict = lr_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, lr_predict))\n",
    "# The logistic regression model scored better in every metric than the svm model\n",
    "# the accuarcy of svm was about 50% while the logistic regression was about 75%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5 - Apply a kernel function to improve SVM performance (4 points)\n",
    "\n",
    "Use the Scikit-learn librariy and apply a kernel function to improve the SVM performance. Check if this is possible. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code Here! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
