{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 7\n",
    "\n",
    "## Your Name Here (or your names here if you are pair programming)\n",
    "\n",
    "Student Name: Tyler Smedley\n",
    "\n",
    "Student UT EID: tws933\n",
    "\n",
    "---\n",
    "\n",
    "Partner Name:\n",
    "\n",
    "Partner UT EID:\n",
    "\n",
    "---\n",
    "\n",
    "Date Created: 03/18/24\n",
    "\n",
    "Date Last Modified: 03/20/24\n",
    "\n",
    "---\n",
    "\n",
    "Totoal Points 20. \n",
    "\n",
    "\n",
    "\n",
    "## Supprt Vector Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Headers\n",
    "# You are welcome to add additional headers here if you wish\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Enable inline mode for matplotlib so that Jupyter displays graphs\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your allowed to use only the above libraries that are imported. No other libs should be used in this assignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Dataset \n",
    "\n",
    "In this Assignment we will work with some patients dataset. \n",
    "\n",
    "We have access to 303 patients data. The features are listed below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPain</th>\n",
       "      <th>RestBP</th>\n",
       "      <th>Chol</th>\n",
       "      <th>Fbs</th>\n",
       "      <th>RestECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExAng</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Thal</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>typical</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>nonanginal</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>nontypical</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>typical</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>reversable</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>nontypical</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>nonanginal</td>\n",
       "      <td>138</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Sex     ChestPain  RestBP  Chol  Fbs  RestECG  MaxHR  ExAng  \\\n",
       "0     63    1       typical     145   233    1        2    150      0   \n",
       "1     67    1  asymptomatic     160   286    0        2    108      1   \n",
       "2     67    1  asymptomatic     120   229    0        2    129      1   \n",
       "3     37    1    nonanginal     130   250    0        0    187      0   \n",
       "4     41    0    nontypical     130   204    0        2    172      0   \n",
       "..   ...  ...           ...     ...   ...  ...      ...    ...    ...   \n",
       "298   45    1       typical     110   264    0        0    132      0   \n",
       "299   68    1  asymptomatic     144   193    1        0    141      0   \n",
       "300   57    1  asymptomatic     130   131    0        0    115      1   \n",
       "301   57    0    nontypical     130   236    0        2    174      0   \n",
       "302   38    1    nonanginal     138   175    0        0    173      0   \n",
       "\n",
       "     Oldpeak  Slope   Ca        Thal Target  \n",
       "0        2.3      3  0.0       fixed     No  \n",
       "1        1.5      2  3.0      normal    Yes  \n",
       "2        2.6      2  2.0  reversable    Yes  \n",
       "3        3.5      3  0.0      normal     No  \n",
       "4        1.4      1  0.0      normal     No  \n",
       "..       ...    ...  ...         ...    ...  \n",
       "298      1.2      2  0.0  reversable    Yes  \n",
       "299      3.4      2  2.0  reversable    Yes  \n",
       "300      1.2      2  1.0  reversable    Yes  \n",
       "301      0.0      2  1.0      normal    Yes  \n",
       "302      0.0      1  NaN      normal     No  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "heart_df = pd.read_csv(\"Heart.csv\")\n",
    "heart_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Age:** The person’s age in years\n",
    "\n",
    "**Sex:** The person’s sex (1 = male, 0 = female)\n",
    "\n",
    "**ChestPain:** chest pain type\n",
    "\n",
    "* Value 0: asymptomatic\n",
    "* Value 1: atypical angina\n",
    "* Value 2: non-anginal pain\n",
    "* Value 3: typical angina\n",
    "\n",
    "**RestBP:** The person’s resting blood pressure (mm Hg on admission to the hospital)\n",
    "\n",
    "**Chol:** The person’s cholesterol measurement in mg/dl\n",
    "\n",
    "**Fbs:** The person’s fasting blood sugar (> 120 mg/dl, 1 = true; 0 = false)\n",
    "restecg: resting electrocardiographic results\n",
    "\n",
    "* Value 0: showing probable or definite left ventricular hypertrophy by Estes’ criteria\n",
    "* Value 1: normal\n",
    "* Value 2: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
    "\n",
    "**RestECG:** The person’s maximum heart rate achieved\n",
    "\n",
    "**MaxHR:** Exercise induced angina (1 = yes; 0 = no)\n",
    "\n",
    "**Oldpeak:** ST depression induced by exercise relative to rest (‘ST’ relates to positions on the ECG plot. See more here)\n",
    "\n",
    "**Slope:** the slope of the peak exercise ST segment — 0: downsloping; 1: flat; 2: upsloping\n",
    "\n",
    "* 0: downsloping; \n",
    "* 1: flat; \n",
    "* 2: upsloping\n",
    "\n",
    "**Ca:** The number of major vessels (0–3)\n",
    "\n",
    "**Thal:** A blood disorder called thalassemia Value 0: NULL (dropped from the dataset previously\n",
    "\n",
    "* Value 1: fixed defect (no blood flow in some part of the heart)\n",
    "* Value 2: normal blood flow\n",
    "* Value 3: reversible defect (a blood flow is observed but it is not normal)\n",
    "\n",
    "**Target:** Heart disease (1 = no, 0= yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task - 1 Implement SVM using libraries (4 points)\n",
    "We want to use **Suppert Vector Machine** to perdict if the patients will have heart problems or not. The column \"Target\" in our datasets includes data about heart diseases. If the patient had heart disease we have a 1 and if not a zero. \n",
    "\n",
    "Prepare your data set for predicting heart disease (\"Target\" column) out of 3 features:\n",
    "\n",
    "* Age of the patient (Column **\"Age\"**)\n",
    "* Gender of the patient (male or female - Column **\"Sex\"**)\n",
    "* Cholestrol level of the patient (Column **\"Chol\"**) \n",
    "\n",
    "\n",
    "Split your data into 80% traning data and 20% test data, and implement Support Vector Machine using Scikit-Learn. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target yes/no to 1/0 and create test/train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "heart_df['Target'] = heart_df['Target'].map({'Yes':1, 'No':0})\n",
    "y = heart_df['Target']\n",
    "X = heart_df[['Age', 'Sex', 'Chol']]\n",
    "\n",
    "y_train, y_test, X_train, X_test = train_test_split(y, X, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn's svm model, fit training data, and predict target values from test data\n",
    "from sklearn import svm\n",
    "\n",
    "svm_model  = svm.SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "target_pred = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 - (4 points)\n",
    "\n",
    "Cacluate the accuracy, Precision, Recall and F1 score of your **SVM** implementaion from Task 1. \n",
    "Print the results. \n",
    "\n",
    "You may use library methods for this task if you choose to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.69      0.62        35\n",
      "           1       0.39      0.27      0.32        26\n",
      "\n",
      "    accuracy                           0.51        61\n",
      "   macro avg       0.47      0.48      0.47        61\n",
      "weighted avg       0.49      0.51      0.49        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use sklearn to calculate and print accuracy, precision, recall, and F1 score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, target_pred))\n",
    "# 0 = no heart problems\n",
    "# 1 = heart problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 - Implement SVM without using libraries  - (4 points)\n",
    "\n",
    "Implement SVM from scratch using Hinge Loss function and Gradient Descent. \n",
    "Try to produce the same result as you get from the libraries. \n",
    "\n",
    "\n",
    "* Do as many iterations as needed \n",
    "* Do maximum **100 iterations**\n",
    "* Use a very small learning rate for checking your GD implementation. \n",
    "* Your are allowed to use your choice of learning rate, like using 0.0001, 0.001 or 0.01 or 0.1 or higher. \n",
    "* Visualize your costs. \n",
    "* No need to add an y-intercept in this task. \n",
    "* You can use libraries to report accuracy, Precision, Recall and F1. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute cost\n",
    "def compute_cost(X, y, W, reg_factor):\n",
    "    n = X.shape[0]\n",
    "    distances = 1 - y *(np.dot(X, W))\n",
    "    distances[distances < 0] = 0\n",
    "\n",
    "    hinge_loss = reg_factor * (np.sum(distances) / n)\n",
    "    return (np.dot(W, W) + hinge_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate gradient\n",
    "def calculate_gradient(X, y, W, reg_factor):\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    distance = 1 - (y * np.dot(X, W))\n",
    "    dw = np.zeros(len(W))\n",
    "\n",
    "    for ind, d  in enumerate(distance):\n",
    "        if d < 0:\n",
    "            di = W\n",
    "        else:\n",
    "            di = W - (reg_factor * y[ind] * X[ind])\n",
    "        dw += di\n",
    "\n",
    "    dw = dw/len(y)\n",
    "    return dw\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Cost is: 0.01 weights [0. 0. 0.]\n",
      "Epoch 1 Cost is: 0.00854866116878287 weights [2.64421488e-04 3.67768595e-06 1.17595041e-03]\n",
      "Epoch 2 Cost is: 0.007101674902720561 weights [5.28578554e-04 7.35169421e-06 2.35072488e-03]\n",
      "Epoch 3 Cost is: 0.005876810055873424 weights [7.92471463e-04 1.10220285e-05 3.52432456e-03]\n",
      "Epoch 4 Cost is: 0.005544600563368137 weights [9.60356677e-04 1.34903453e-05 4.18749445e-03]\n",
      "Epoch 5 Cost is: 0.005473077462807743 weights [1.04042938e-03 1.47991690e-05 4.47326564e-03]\n",
      "Epoch 6 Cost is: 0.0054419610963325265 weights [1.09257077e-03 1.56521384e-05 4.65098245e-03]\n",
      "Epoch 7 Cost is: 0.005423896939203595 weights [1.13304844e-03 1.63389656e-05 4.78633147e-03]\n",
      "Epoch 8 Cost is: 0.005412203719235657 weights [1.16600631e-03 1.69424614e-05 4.89716498e-03]\n",
      "Epoch 9 Cost is: 0.005403405112646069 weights [1.19566675e-03 1.74627090e-05 4.99156533e-03]\n",
      "Epoch 10 Cost is: 0.005397602469731894 weights [1.22046281e-03 1.78997917e-05 5.07037542e-03]\n",
      "Epoch 11 Cost is: 0.005393521080823902 weights [1.24089524e-03 1.82537928e-05 5.13373480e-03]\n",
      "Epoch 12 Cost is: 0.005389452624053414 weights [1.26130724e-03 1.86074398e-05 5.19703081e-03]\n",
      "Epoch 13 Cost is: 0.005385941496234177 weights [1.28169883e-03 1.89607332e-05 5.26026353e-03]\n",
      "Epoch 14 Cost is: 0.0053843050340159505 weights [1.29430142e-03 1.91897063e-05 5.30165616e-03]\n",
      "Epoch 15 Cost is: 0.005382753618971317 weights [1.30689142e-03 1.94184505e-05 5.34300740e-03]\n",
      "Epoch 16 Cost is: 0.005381678246468211 weights [1.31769197e-03 1.96056436e-05 5.37700324e-03]\n",
      "Epoch 17 Cost is: 0.005380606490329038 weights [1.32848171e-03 1.97926496e-05 5.41096507e-03]\n",
      "Epoch 18 Cost is: 0.005379538341857994 weights [1.33926067e-03 1.99794685e-05 5.44489295e-03]\n",
      "Epoch 19 Cost is: 0.0053784737923781205 weights [1.35002885e-03 2.01661006e-05 5.47878690e-03]\n",
      "Epoch 20 Cost is: 0.005377577621081938 weights [1.36078626e-03 2.03525461e-05 5.51264696e-03]\n",
      "Epoch 21 Cost is: 0.005376942169753908 weights [1.36983869e-03 2.04974828e-05 5.53936572e-03]\n",
      "Epoch 22 Cost is: 0.005376364943808059 weights [1.37888208e-03 2.06422745e-05 5.56605776e-03]\n",
      "Epoch 23 Cost is: 0.005376128045651882 weights [1.38609824e-03 2.07455992e-05 5.58573963e-03]\n",
      "Epoch 24 Cost is: 0.005376019013957649 weights [1.39074520e-03 2.08488205e-05 5.59862497e-03]\n",
      "Epoch 25 Cost is: 0.005375910466005864 weights [1.39538751e-03 2.09519387e-05 5.61149742e-03]\n",
      "Epoch 26 Cost is: 0.0053758024005637435 weights [1.40002518e-03 2.10549537e-05 5.62435699e-03]\n",
      "Epoch 27 Cost is: 0.0053756948164012264 weights [1.40465821e-03 2.11578657e-05 5.63720371e-03]\n",
      "Epoch 28 Cost is: 0.005375587712290977 weights [1.40928661e-03 2.12606747e-05 5.65003758e-03]\n",
      "Epoch 29 Cost is: 0.0053755751022129695 weights [1.41391038e-03 2.13633810e-05 5.66285862e-03]\n",
      "Epoch 30 Cost is: 0.005375569094278838 weights [1.41687664e-03 2.14246622e-05 5.66876601e-03]\n",
      "Epoch 31 Cost is: 0.005375563179620931 weights [1.41983993e-03 2.14858822e-05 5.67466749e-03]\n",
      "Epoch 32 Cost is: 0.00537555735797152 weights [1.42280025e-03 2.15470410e-05 5.68056307e-03]\n",
      "Epoch 33 Cost is: 0.0053755516290634985 weights [1.42575762e-03 2.16081385e-05 5.68645275e-03]\n",
      "Epoch 34 Cost is: 0.005375545992630371 weights [1.42871202e-03 2.16691750e-05 5.69233655e-03]\n",
      "Epoch 35 Cost is: 0.005375540448406258 weights [1.43166348e-03 2.17301505e-05 5.69821446e-03]\n",
      "Epoch 36 Cost is: 0.00537553499612589 weights [1.43461198e-03 2.17910650e-05 5.70408649e-03]\n",
      "Epoch 37 Cost is: 0.005375529635524614 weights [1.43755753e-03 2.18519185e-05 5.70995266e-03]\n",
      "Epoch 38 Cost is: 0.005375524366338382 weights [1.44050014e-03 2.19127112e-05 5.71581295e-03]\n",
      "Epoch 39 Cost is: 0.005375519188303756 weights [1.44343981e-03 2.19734432e-05 5.72166739e-03]\n",
      "Epoch 40 Cost is: 0.005375514101157905 weights [1.44637653e-03 2.20341143e-05 5.72751597e-03]\n",
      "Epoch 41 Cost is: 0.005375509104638604 weights [1.44931032e-03 2.20947249e-05 5.73335870e-03]\n",
      "Epoch 42 Cost is: 0.005375504198484234 weights [1.45224118e-03 2.21552748e-05 5.73919559e-03]\n",
      "Epoch 43 Cost is: 0.00537549938243378 weights [1.45516910e-03 2.22157641e-05 5.74502664e-03]\n",
      "Epoch 44 Cost is: 0.005375494656226826 weights [1.45809410e-03 2.22761930e-05 5.75085186e-03]\n",
      "Epoch 45 Cost is: 0.0053754900196035585 weights [1.46101617e-03 2.23365614e-05 5.75667126e-03]\n",
      "Epoch 46 Cost is: 0.005375485472304765 weights [1.46393532e-03 2.23968695e-05 5.76248483e-03]\n",
      "Epoch 47 Cost is: 0.0053754810140718284 weights [1.46685155e-03 2.24571172e-05 5.76829260e-03]\n",
      "Epoch 48 Cost is: 0.005375476644646731 weights [1.46976486e-03 2.25173047e-05 5.77409455e-03]\n",
      "Epoch 49 Cost is: 0.005375472363772052 weights [1.47267526e-03 2.25774321e-05 5.77989071e-03]\n",
      "Epoch 50 Cost is: 0.005375468171190959 weights [1.47558275e-03 2.26374993e-05 5.78568106e-03]\n",
      "Epoch 51 Cost is: 0.00537546406664722 weights [1.47848733e-03 2.26975064e-05 5.79146563e-03]\n",
      "Epoch 52 Cost is: 0.005375460049885192 weights [1.48138901e-03 2.27574535e-05 5.79724441e-03]\n",
      "Epoch 53 Cost is: 0.0053754561206498215 weights [1.48428779e-03 2.28173407e-05 5.80301742e-03]\n",
      "Epoch 54 Cost is: 0.005375452278686646 weights [1.48718366e-03 2.28771680e-05 5.80878465e-03]\n",
      "Epoch 55 Cost is: 0.00537544852374179 weights [1.49007665e-03 2.29369354e-05 5.81454611e-03]\n",
      "Epoch 56 Cost is: 0.005375444855561968 weights [1.49296673e-03 2.29966431e-05 5.82030181e-03]\n",
      "Epoch 57 Cost is: 0.005375441273894476 weights [1.49585393e-03 2.30562911e-05 5.82605176e-03]\n",
      "Epoch 58 Cost is: 0.005375437778487195 weights [1.49873824e-03 2.31158795e-05 5.83179595e-03]\n",
      "Epoch 59 Cost is: 0.005375434369088592 weights [1.50161967e-03 2.31754082e-05 5.83753441e-03]\n",
      "Epoch 60 Cost is: 0.005375431045447716 weights [1.50449822e-03 2.32348774e-05 5.84326712e-03]\n",
      "Epoch 61 Cost is: 0.0053754278073141915 weights [1.50737388e-03 2.32942872e-05 5.84899410e-03]\n",
      "Epoch 62 Cost is: 0.005375424654438227 weights [1.51024668e-03 2.33536375e-05 5.85471535e-03]\n",
      "Epoch 63 Cost is: 0.005375421586570609 weights [1.51311659e-03 2.34129285e-05 5.86043089e-03]\n",
      "Epoch 64 Cost is: 0.0053754186034627 weights [1.51598364e-03 2.34721602e-05 5.86614070e-03]\n",
      "Epoch 65 Cost is: 0.0053754157048664375 weights [1.51884782e-03 2.35313327e-05 5.87184481e-03]\n",
      "Epoch 66 Cost is: 0.005375412890534335 weights [1.52170914e-03 2.35904460e-05 5.87754321e-03]\n",
      "Epoch 67 Cost is: 0.005375410160219479 weights [1.52456760e-03 2.36495002e-05 5.88323592e-03]\n",
      "Epoch 68 Cost is: 0.005375407513675526 weights [1.52742320e-03 2.37084953e-05 5.88892293e-03]\n",
      "Epoch 69 Cost is: 0.005375404950656705 weights [1.53027594e-03 2.37674314e-05 5.89460426e-03]\n",
      "Epoch 70 Cost is: 0.005375402470917816 weights [1.53312583e-03 2.38263086e-05 5.90027990e-03]\n",
      "Epoch 71 Cost is: 0.005375400074214227 weights [1.53597287e-03 2.38851269e-05 5.90594987e-03]\n",
      "Epoch 72 Cost is: 0.005375397760301869 weights [1.53881706e-03 2.39438864e-05 5.91161417e-03]\n",
      "Epoch 73 Cost is: 0.0053753955289372445 weights [1.54165841e-03 2.40025872e-05 5.91727280e-03]\n",
      "Epoch 74 Cost is: 0.005375393379877418 weights [1.54449691e-03 2.40612292e-05 5.92292577e-03]\n",
      "Epoch 75 Cost is: 0.005375391312880015 weights [1.54733258e-03 2.41198126e-05 5.92857310e-03]\n",
      "Epoch 76 Cost is: 0.0053753893277032295 weights [1.55016542e-03 2.41783374e-05 5.93421477e-03]\n",
      "Epoch 77 Cost is: 0.005375387424105815 weights [1.55299542e-03 2.42368037e-05 5.93985081e-03]\n",
      "Epoch 78 Cost is: 0.005375385601847079 weights [1.55582259e-03 2.42952115e-05 5.94548120e-03]\n",
      "Epoch 79 Cost is: 0.005375383860686893 weights [1.55864693e-03 2.43535610e-05 5.95110597e-03]\n",
      "Epoch 80 Cost is: 0.005375382200385687 weights [1.56146845e-03 2.44118520e-05 5.95672511e-03]\n",
      "Epoch 81 Cost is: 0.005375380620704447 weights [1.56428714e-03 2.44700848e-05 5.96233863e-03]\n",
      "Epoch 82 Cost is: 0.005375379121404708 weights [1.56710302e-03 2.45282593e-05 5.96794654e-03]\n",
      "Epoch 83 Cost is: 0.005375377702248566 weights [1.56991608e-03 2.45863757e-05 5.97354884e-03]\n",
      "Epoch 84 Cost is: 0.005375376362998668 weights [1.57272633e-03 2.46444340e-05 5.97914554e-03]\n",
      "Epoch 85 Cost is: 0.0053753751034182114 weights [1.57553377e-03 2.47024342e-05 5.98473665e-03]\n",
      "Epoch 86 Cost is: 0.005375373923270943 weights [1.57833840e-03 2.47603764e-05 5.99032216e-03]\n",
      "Epoch 87 Cost is: 0.005375372822321166 weights [1.58114023e-03 2.48182606e-05 5.99590208e-03]\n",
      "Epoch 88 Cost is: 0.005375371800333719 weights [1.58393926e-03 2.48760870e-05 6.00147643e-03]\n",
      "Epoch 89 Cost is: 0.005375370857074001 weights [1.58673548e-03 2.49338555e-05 6.00704520e-03]\n",
      "Epoch 90 Cost is: 0.005375369992307947 weights [1.58952891e-03 2.49915663e-05 6.01260840e-03]\n",
      "Epoch 91 Cost is: 0.005375369205802041 weights [1.59231955e-03 2.50492193e-05 6.01816604e-03]\n",
      "Epoch 92 Cost is: 0.005375368497323309 weights [1.59510739e-03 2.51068148e-05 6.02371812e-03]\n",
      "Epoch 93 Cost is: 0.005375367866639321 weights [1.59789245e-03 2.51643526e-05 6.02926465e-03]\n",
      "Epoch 94 Cost is: 0.005375367313518186 weights [1.60067472e-03 2.52218328e-05 6.03480564e-03]\n",
      "Epoch 95 Cost is: 0.005375366837728552 weights [1.60345421e-03 2.52792556e-05 6.04034108e-03]\n",
      "Epoch 96 Cost is: 0.005375366439039611 weights [1.60623093e-03 2.53366210e-05 6.04587099e-03]\n",
      "Epoch 97 Cost is: 0.005375366117221088 weights [1.60900486e-03 2.53939290e-05 6.05139536e-03]\n",
      "Epoch 98 Cost is: 0.0053753658720432414 weights [1.61177602e-03 2.54511797e-05 6.05691422e-03]\n",
      "Epoch 99 Cost is: 0.005375365703276877 weights [1.61454441e-03 2.55083732e-05 6.06242755e-03]\n"
     ]
    }
   ],
   "source": [
    "weights  = np.zeros(X.shape[1])\n",
    "\n",
    "# optimize SVM using gradient descent\n",
    "num_iterations = 100\n",
    "learning_rate = 0.001\n",
    "regularization = 0.01\n",
    "cost_list = []\n",
    "\n",
    "for i in range(0, num_iterations):\n",
    "    cost = compute_cost(X_train, y_train, weights, regularization)\n",
    "    print(\"Epoch\", i, \"Cost is:\", cost, \"weights\", weights)\n",
    "    cost_list.append(cost)\n",
    "    gradient = calculate_gradient(X_train, y_train, weights, regularization)\n",
    "    \n",
    "    weights = weights - learning_rate * gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(num_iterations), cost_list)\n",
    "plt.title(\"Costs\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.4262295081967213\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# prediction calculation\n",
    "target_pred_2 = np.where(np.dot(X_test, weights)<0, -1, 1)\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, target_pred_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4 - Compare SVM results with Logistic Regression - (4 points)\n",
    "\n",
    "Which model performs better here? Compare your results wit the logistic regression. You can use libraries for this task, it is not necessary to implement logistic regression from sratch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.74      0.78        35\n",
      "           1       0.69      0.77      0.73        26\n",
      "\n",
      "    accuracy                           0.75        61\n",
      "   macro avg       0.75      0.76      0.75        61\n",
      "weighted avg       0.76      0.75      0.76        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_predict = lr_model.predict(X_test)\n",
    "\n",
    "cr = classification_report(y_test, lr_predict)\n",
    "print(cr)\n",
    "# The logistic regression model scored better in every metric than the svm model\n",
    "# the accuarcy of svm was about 50% while the logistic regression was about 75%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5 - Apply a kernel function to improve SVM performance (4 points)\n",
    "\n",
    "Use the Scikit-learn librariy and apply a kernel function to improve the SVM performance. Check if this is possible. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.83      0.75        29\n",
      "           1       0.81      0.66      0.72        32\n",
      "\n",
      "    accuracy                           0.74        61\n",
      "   macro avg       0.75      0.74      0.74        61\n",
      "weighted avg       0.75      0.74      0.74        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add your code Here! \n",
    "kernel_model = svm.SVC(kernel = 'linear')\n",
    "kernel_model.fit(X_train, y_train)\n",
    "ker_pred = kernel_model.predict(X_test)\n",
    "print(classification_report(ker_pred, y_test))\n",
    "\n",
    "# adding a linear kernel to the prediction imporoved the accuracy to 74% from about 50%\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
